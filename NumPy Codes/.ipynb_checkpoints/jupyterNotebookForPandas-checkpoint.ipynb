{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b0d6ce7-333d-4218-b646-2ece96c58401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcefe920-6f01-475d-8b2a-2401f54ee467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       EEID        Full Name                 Job Title  Department  \\\n",
      "0    E02387      Emily Davis                Sr. Manger          IT   \n",
      "1    E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2    E02572     Luna Sanders                  Director     Finance   \n",
      "3    E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4    E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "..      ...              ...                       ...         ...   \n",
      "995  E03094     Wesley Young               Sr. Analyst   Marketing   \n",
      "996  E01909     Lillian Khan                   Analyst     Finance   \n",
      "997  E04398      Oliver Yang                  Director   Marketing   \n",
      "998  E02521      Lily Nguyen               Sr. Analyst     Finance   \n",
      "999  E03545      Sofia Cheng            Vice President  Accounting   \n",
      "\n",
      "              Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0    Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1             Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2       Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3             Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4             Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "..                      ...     ...        ...  ...        ...            ...   \n",
      "995     Speciality Products    Male  Caucasian   33 2016-09-18          98427   \n",
      "996     Speciality Products  Female      Asian   44 2010-05-31          47387   \n",
      "997     Speciality Products    Male      Asian   31 2019-06-10         176710   \n",
      "998     Speciality Products  Female      Asian   33 2012-01-28          95960   \n",
      "999               Corporate  Female      Asian   63 2020-07-26         216195   \n",
      "\n",
      "     Bonus %        Country       City  Exit Date  \n",
      "0       0.15  United States    Seattle 2021-10-16  \n",
      "1       0.00          China  Chongqing        NaT  \n",
      "2       0.20  United States    Chicago        NaT  \n",
      "3       0.07  United States    Chicago        NaT  \n",
      "4       0.00  United States    Phoenix        NaT  \n",
      "..       ...            ...        ...        ...  \n",
      "995     0.00  United States   Columbus        NaT  \n",
      "996     0.00          China    Chengdu 2018-01-08  \n",
      "997     0.15  United States      Miami        NaT  \n",
      "998     0.00          China    Chengdu        NaT  \n",
      "999     0.31  United States      Miami        NaT  \n",
      "\n",
      "[1000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Reading an Excel file\n",
    "data = pd.read_excel(\"ESD.xlsx\")\n",
    "print(data)\n",
    "\n",
    "# Note - If there is a large amount of data then it will show starting 5 records and the last 5 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb4ad407-5db0-4176-b0e3-de2e292b03f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     EEID        Full Name                 Job Title  Department  \\\n",
      "0  E02387      Emily Davis                Sr. Manger          IT   \n",
      "1  E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2  E02572     Luna Sanders                  Director     Finance   \n",
      "3  E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4  E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "5  E00644     Joshua Gupta    Account Representative       Sales   \n",
      "6  E01550      Ruby Barnes                   Manager          IT   \n",
      "7  E04332      Luke Martin                   Analyst     Finance   \n",
      "8  E04533    Easton Bailey                   Manager  Accounting   \n",
      "9  E03838  Madeline Walker               Sr. Analyst     Finance   \n",
      "\n",
      "            Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0  Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1           Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2     Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3           Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4           Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "5               Corporate    Male      Asian   57 2017-01-24          50994   \n",
      "6               Corporate  Female  Caucasian   27 2020-07-01         119746   \n",
      "7           Manufacturing    Male      Black   25 2020-05-16          41336   \n",
      "8           Manufacturing    Male  Caucasian   29 2019-01-25         113527   \n",
      "9     Speciality Products  Female  Caucasian   34 2018-06-13          77203   \n",
      "\n",
      "   Bonus %        Country       City  Exit Date  \n",
      "0     0.15  United States    Seattle 2021-10-16  \n",
      "1     0.00          China  Chongqing        NaT  \n",
      "2     0.20  United States    Chicago        NaT  \n",
      "3     0.07  United States    Chicago        NaT  \n",
      "4     0.00  United States    Phoenix        NaT  \n",
      "5     0.00          China  Chongqing        NaT  \n",
      "6     0.10  United States    Phoenix        NaT  \n",
      "7     0.00  United States      Miami 2021-05-20  \n",
      "8     0.06  United States     Austin        NaT  \n",
      "9     0.00  United States    Chicago        NaT  \n",
      "       EEID          Full Name             Job Title       Department  \\\n",
      "990  E01578       Anthony Hong            Sr. Manger               IT   \n",
      "991  E03430        Leo Herrera  Sr. Business Partner  Human Resources   \n",
      "992  E03058      Robert Wright   Technical Architect               IT   \n",
      "993  E04762  Audrey Richardson              Director               IT   \n",
      "994  E01148     Scarlett Kumar       Systems Analyst               IT   \n",
      "995  E03094       Wesley Young           Sr. Analyst        Marketing   \n",
      "996  E01909       Lillian Khan               Analyst          Finance   \n",
      "997  E04398        Oliver Yang              Director        Marketing   \n",
      "998  E02521        Lily Nguyen           Sr. Analyst          Finance   \n",
      "999  E03545        Sofia Cheng        Vice President       Accounting   \n",
      "\n",
      "              Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "990  Research & Development    Male      Asian   37 2010-11-29         146961   \n",
      "991  Research & Development    Male     Latino   48 1998-04-22          85369   \n",
      "992           Manufacturing    Male  Caucasian   30 2015-06-14          67489   \n",
      "993           Manufacturing  Female  Caucasian   46 2018-10-06         166259   \n",
      "994               Corporate  Female      Asian   55 2009-01-07          47032   \n",
      "995     Speciality Products    Male  Caucasian   33 2016-09-18          98427   \n",
      "996     Speciality Products  Female      Asian   44 2010-05-31          47387   \n",
      "997     Speciality Products    Male      Asian   31 2019-06-10         176710   \n",
      "998     Speciality Products  Female      Asian   33 2012-01-28          95960   \n",
      "999               Corporate  Female      Asian   63 2020-07-26         216195   \n",
      "\n",
      "     Bonus %        Country      City  Exit Date  \n",
      "990     0.11  United States  Columbus        NaT  \n",
      "991     0.00         Brazil    Manaus 2004-11-27  \n",
      "992     0.00  United States   Chicago        NaT  \n",
      "993     0.17  United States   Chicago        NaT  \n",
      "994     0.00  United States  Columbus        NaT  \n",
      "995     0.00  United States  Columbus        NaT  \n",
      "996     0.00          China   Chengdu 2018-01-08  \n",
      "997     0.15  United States     Miami        NaT  \n",
      "998     0.00          China   Chengdu        NaT  \n",
      "999     0.31  United States     Miami        NaT  \n"
     ]
    }
   ],
   "source": [
    "# Exploring data in pandas\n",
    "\n",
    "print(data.head(10)) # to see n values from the starting.\n",
    "print(data.tail(10)) # to see n values from the end.\n",
    "\n",
    "# Note - for head() and tail() default values is 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16ff9ce5-4836-4410-903a-8dc73e999a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   EEID           1000 non-null   object        \n",
      " 1   Full Name      1000 non-null   object        \n",
      " 2   Job Title      1000 non-null   object        \n",
      " 3   Department     1000 non-null   object        \n",
      " 4   Business Unit  1000 non-null   object        \n",
      " 5   Gender         1000 non-null   object        \n",
      " 6   Ethnicity      1000 non-null   object        \n",
      " 7   Age            1000 non-null   int64         \n",
      " 8   Hire Date      1000 non-null   datetime64[ns]\n",
      " 9   Annual Salary  1000 non-null   int64         \n",
      " 10  Bonus %        1000 non-null   float64       \n",
      " 11  Country        1000 non-null   object        \n",
      " 12  City           1000 non-null   object        \n",
      " 13  Exit Date      85 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(1), int64(2), object(9)\n",
      "memory usage: 109.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# to know all the information related to our data like class, rangeIndex, total col, Non-Null count for every col, the datatype of col, memory usage, etc. \n",
    "\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996262e4-d1d8-46f7-85a6-93671556402c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Hire Date</th>\n",
       "      <th>Annual Salary</th>\n",
       "      <th>Bonus %</th>\n",
       "      <th>Exit Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44.382000</td>\n",
       "      <td>2012-04-07 02:54:14.400000</td>\n",
       "      <td>113217.365000</td>\n",
       "      <td>0.088660</td>\n",
       "      <td>2016-11-02 18:04:14.117647104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>1992-01-09 00:00:00</td>\n",
       "      <td>40063.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1994-12-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>2007-02-14 00:00:00</td>\n",
       "      <td>71430.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2014-12-25 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>2014-02-15 12:00:00</td>\n",
       "      <td>96557.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019-05-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>2018-06-22 00:00:00</td>\n",
       "      <td>150782.250000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>2021-04-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>2021-12-26 00:00:00</td>\n",
       "      <td>258498.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2022-08-17 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.246981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53545.985644</td>\n",
       "      <td>0.117856</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age                   Hire Date  Annual Salary      Bonus %  \\\n",
       "count  1000.000000                        1000    1000.000000  1000.000000   \n",
       "mean     44.382000  2012-04-07 02:54:14.400000  113217.365000     0.088660   \n",
       "min      25.000000         1992-01-09 00:00:00   40063.000000     0.000000   \n",
       "25%      35.000000         2007-02-14 00:00:00   71430.250000     0.000000   \n",
       "50%      45.000000         2014-02-15 12:00:00   96557.000000     0.000000   \n",
       "75%      54.000000         2018-06-22 00:00:00  150782.250000     0.150000   \n",
       "max      65.000000         2021-12-26 00:00:00  258498.000000     0.400000   \n",
       "std      11.246981                         NaN   53545.985644     0.117856   \n",
       "\n",
       "                           Exit Date  \n",
       "count                             85  \n",
       "mean   2016-11-02 18:04:14.117647104  \n",
       "min              1994-12-18 00:00:00  \n",
       "25%              2014-12-25 00:00:00  \n",
       "50%              2019-05-23 00:00:00  \n",
       "75%              2021-04-09 00:00:00  \n",
       "max              2022-08-17 00:00:00  \n",
       "std                              NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It provides a quick overview of the statistical properties of the numerical columns in a DataFrame.\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef7fdc4a-bf57-4068-8e3d-44cf43d86788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEID               0\n",
      "Full Name          0\n",
      "Job Title          0\n",
      "Department         0\n",
      "Business Unit      0\n",
      "Gender             0\n",
      "Ethnicity          0\n",
      "Age                0\n",
      "Hire Date          0\n",
      "Annual Salary      0\n",
      "Bonus %            0\n",
      "Country            0\n",
      "City               0\n",
      "Exit Date        915\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# It provides a column-wise count of null values. \n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba9d050d-5d21-478f-a4a4-80f5c43eb511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling duplicates using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d1741c2-f510-4771-915a-3fc27e5c0801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F      NaN\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05       NaN      M  25000.0\n",
      "5  EMP06     rohit      M      NaN\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('company1.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2934099e-d9b0-45fe-81ba-f52af57108aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# To show the count of all the existing duplicates.\n",
    "print(data['EEID'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80e5c5f9-54dc-4e80-9ab6-7ccb11d416f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID    Name gender   salary\n",
      "0  EMP01  ayushi      F      NaN\n",
      "1  EMP02   rohit      M  25000.0\n",
      "3  EMP01  ayushi      F  20000.0\n",
      "6  EMP02   rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "# To show only duplicate records.\n",
    "print(data[data['EEID'].duplicated(keep=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c8a2805-f408-45a9-b7a2-36475630bf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F      NaN\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "4  EMP05       NaN      M  25000.0\n",
      "5  EMP06     rohit      M      NaN\n"
     ]
    }
   ],
   "source": [
    "# To remove the duplicates. Always take col which must be having unique values to check for duplicates.\n",
    "data_no_duplicates = data.drop_duplicates(\"EEID\")\n",
    "print(data_no_duplicates)\n",
    "# Note - drop_duplicates() method does not modify the original Data in the CSV file directly. It creates a new DataFrame with the duplicates removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af0c8db3-d447-4fb6-ac26-0c6623f40f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save the new data with no duplicates to existing or new file\n",
    "\n",
    "# Save the DataFrame without duplicates back to a CSV file or Overwrite the original CSV file\n",
    "data_no_duplicates.to_csv('company1_no_duplicates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6954bdb6-25be-415e-9f39-2fad2c483ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with missing data in pandas\n",
    "\n",
    "# Handling Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b275cad-0be7-4f18-8c08-99b7af8f29fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F      NaN\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05       NaN      M  25000.0\n",
      "5  EMP06     rohit      M      NaN\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('company1.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e82d1a3-8e9c-4ac6-b997-8646e5b1f34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEID      0\n",
      "Name      1\n",
      "gender    1\n",
      "salary    2\n",
      "dtype: int64\n",
      "EEID      0\n",
      "Name      1\n",
      "gender    1\n",
      "salary    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# NaN stands for \"Not a Number.\" It is used to represent missing or undefined values in datasets.\n",
    "\n",
    "print(data.isnull().sum())\n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0a3a3bf-8c30-4b73-ae00-fcd567576ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID    Name gender   salary\n",
      "1  EMP02   rohit      M  25000.0\n",
      "3  EMP01  ayushi      F  20000.0\n",
      "6  EMP02   rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with any null values.\n",
    "\n",
    "print(data.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf3e8540-e9d9-4bd7-99bb-de46ab56d38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F      0.0\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali      0  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05         0      M  25000.0\n",
      "5  EMP06     rohit      M      0.0\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "# replacing or filling null values.\n",
    "\n",
    "# fillna() method allows you to replace null values with a specified value\n",
    "\n",
    "print(data.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "accbb84e-7850-472f-82aa-334e7b8fae15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F      NaN\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali      M  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05    ayushi      M  25000.0\n",
      "5  EMP06     rohit      M  25000.0\n",
      "6  EMP02     rohit      M  25000.0\n",
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F  25000.0\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali      F  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05     rohit      M  25000.0\n",
      "5  EMP06     rohit      M  25000.0\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_11964\\1931289420.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  print(data.fillna(method='ffill'))\n",
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_11964\\1931289420.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  print(data.fillna(method='bfill'))\n"
     ]
    }
   ],
   "source": [
    "# You can propagate the last valid observation forward or backward to fill null values.\n",
    "\n",
    "print(data.fillna(method='ffill'))\n",
    "print(data.fillna(method='bfill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5aeaf6b1-62df-4f05-af19-16d582d253d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F  30000.0\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05       NaN      M  25000.0\n",
      "5  EMP06     rohit      M  30000.0\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "# Use the replace() method to substitute null values with another value.\n",
    "\n",
    "import numpy as np\n",
    "data[\"salary\"] = data['salary'].replace(np.nan,30000)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "793e61a8-589e-4f72-ac22-83a324361b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F  24400.0\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05       NaN      M  25000.0\n",
      "5  EMP06     rohit      M  24400.0\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "# Replace null values with statistical measures such as the mean, median, or mode of the column.\n",
    "\n",
    "data = pd.read_csv('company1.csv')\n",
    "\n",
    "salary_mean = data[\"salary\"].mean()\n",
    "\n",
    "data[\"salary\"] = data['salary'].replace(np.nan,salary_mean)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29635301-e744-4051-9c21-eb2feaf5c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column transformation in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ae9af92-e018-40ff-bf8c-a730865aa1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     EEID        Full Name                 Job Title  Department  \\\n",
      "0  E02387      Emily Davis                Sr. Manger          IT   \n",
      "1  E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2  E02572     Luna Sanders                  Director     Finance   \n",
      "3  E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4  E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "5  E00644     Joshua Gupta    Account Representative       Sales   \n",
      "6  E01550      Ruby Barnes                   Manager          IT   \n",
      "7  E04332      Luke Martin                   Analyst     Finance   \n",
      "8  E04533    Easton Bailey                   Manager  Accounting   \n",
      "9  E03838  Madeline Walker               Sr. Analyst     Finance   \n",
      "\n",
      "            Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0  Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1           Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2     Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3           Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4           Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "5               Corporate    Male      Asian   57 2017-01-24          50994   \n",
      "6               Corporate  Female  Caucasian   27 2020-07-01         119746   \n",
      "7           Manufacturing    Male      Black   25 2020-05-16          41336   \n",
      "8           Manufacturing    Male  Caucasian   29 2019-01-25         113527   \n",
      "9     Speciality Products  Female  Caucasian   34 2018-06-13          77203   \n",
      "\n",
      "   Bonus %        Country       City  Exit Date  \n",
      "0     0.15  United States    Seattle 2021-10-16  \n",
      "1     0.00          China  Chongqing        NaT  \n",
      "2     0.20  United States    Chicago        NaT  \n",
      "3     0.07  United States    Chicago        NaT  \n",
      "4     0.00  United States    Phoenix        NaT  \n",
      "5     0.00          China  Chongqing        NaT  \n",
      "6     0.10  United States    Phoenix        NaT  \n",
      "7     0.00  United States      Miami 2021-05-20  \n",
      "8     0.06  United States     Austin        NaT  \n",
      "9     0.00  United States    Chicago        NaT  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('ESD.xlsx')\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "469e25dc-3f19-4eb2-9ff6-5f8ef3876593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     EEID        Full Name                 Job Title  Department  \\\n",
      "0  E02387      Emily Davis                Sr. Manger          IT   \n",
      "1  E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2  E02572     Luna Sanders                  Director     Finance   \n",
      "3  E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4  E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "5  E00644     Joshua Gupta    Account Representative       Sales   \n",
      "6  E01550      Ruby Barnes                   Manager          IT   \n",
      "7  E04332      Luke Martin                   Analyst     Finance   \n",
      "8  E04533    Easton Bailey                   Manager  Accounting   \n",
      "9  E03838  Madeline Walker               Sr. Analyst     Finance   \n",
      "\n",
      "            Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0  Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1           Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2     Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3           Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4           Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "5               Corporate    Male      Asian   57 2017-01-24          50994   \n",
      "6               Corporate  Female  Caucasian   27 2020-07-01         119746   \n",
      "7           Manufacturing    Male      Black   25 2020-05-16          41336   \n",
      "8           Manufacturing    Male  Caucasian   29 2019-01-25         113527   \n",
      "9     Speciality Products  Female  Caucasian   34 2018-06-13          77203   \n",
      "\n",
      "   Bonus %        Country       City  Exit Date Get Bonus  \n",
      "0     0.15  United States    Seattle 2021-10-16     Bonus  \n",
      "1     0.00          China  Chongqing        NaT   NoBonus  \n",
      "2     0.20  United States    Chicago        NaT     Bonus  \n",
      "3     0.07  United States    Chicago        NaT     Bonus  \n",
      "4     0.00  United States    Phoenix        NaT   NoBonus  \n",
      "5     0.00          China  Chongqing        NaT   NoBonus  \n",
      "6     0.10  United States    Phoenix        NaT     Bonus  \n",
      "7     0.00  United States      Miami 2021-05-20   NoBonus  \n",
      "8     0.06  United States     Austin        NaT     Bonus  \n",
      "9     0.00  United States    Chicago        NaT   NoBonus  \n"
     ]
    }
   ],
   "source": [
    "# Create a get bonus column to populate values if emp is getting a bonus and not based on the bonus column.\n",
    "\n",
    "data.loc[(data[\"Bonus %\"] == 0),\"Get Bonus\"] = \"NoBonus\"\n",
    "data.loc[(data[\"Bonus %\"] > 0),\"Get Bonus\"] = \"Bonus\"\n",
    "\n",
    "print(data.head(10))\n",
    "\n",
    "# Note - data.loc[] is an accessor used for label-based indexing to Access rows and columns using labels, Filter rows based on boolean conditions,\n",
    "# Modify values in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c71137ab-5b47-45cf-a85f-cf8e68fdaa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id  customer_acct_num first_name  last_name  \\\n",
      "0            1        87462024688      Sheri     Nowmer   \n",
      "1            2        87470586299    Derrick    Whelply   \n",
      "2            3        87475757600     Jeanne      Derry   \n",
      "3            4        87500482201    Michael     Spence   \n",
      "4            5        87514054179       Maya  Gutierrez   \n",
      "5            6        87517782449     Robert    Damstra   \n",
      "6            7        87521172800    Rebecca   Kanagaki   \n",
      "7            8        87539744377        Kim    Brunner   \n",
      "8            9        87544797658     Brenda   Blumberg   \n",
      "9           10        87568712234     Darren      Stanz   \n",
      "\n",
      "         customer_address customer_city customer_state_province  \\\n",
      "0        2433 Bailey Road      Tlaxiaco                  Oaxaca   \n",
      "1      2219 Dewing Avenue         Sooke                      BC   \n",
      "2         7640 First Ave.      Issaquah                      WA   \n",
      "3           337 Tosca Way       Burnaby                      BC   \n",
      "4         8668 Via Neruda        Novato                      CA   \n",
      "5     1619 Stillman Court      Lynnwood                      WA   \n",
      "6  2860 D Mt. Hood Circle      Tlaxiaco                  Oaxaca   \n",
      "7       6064 Brodia Court    San Andres                      DF   \n",
      "8        7560 Trees Drive      Richmond                      BC   \n",
      "9         1019 Kenwal Rd.   Lake Oswego                      OR   \n",
      "\n",
      "   customer_postal_code customer_country  birthdate marital_status  \\\n",
      "0                 15057           Mexico  8/26/1961              M   \n",
      "1                 17172           Canada   7/3/1915              S   \n",
      "2                 73980              USA  6/21/1910              M   \n",
      "3                 74674           Canada  6/20/1969              M   \n",
      "4                 57355              USA  5/10/1951              S   \n",
      "5                 90792              USA  10/8/1942              S   \n",
      "6                 13343           Mexico  3/27/1949              M   \n",
      "7                 12942           Mexico  8/10/1922              M   \n",
      "8                 17256           Canada  6/23/1979              M   \n",
      "9                 82017              USA  8/26/1949              S   \n",
      "\n",
      "  yearly_income gender  total_children  num_children_at_home  \\\n",
      "0   $30K - $50K      F               4                     2   \n",
      "1   $70K - $90K      M               1                     0   \n",
      "2   $50K - $70K      F               1                     1   \n",
      "3   $10K - $30K      M               4                     4   \n",
      "4   $30K - $50K      F               3                     0   \n",
      "5   $70K - $90K      F               3                     0   \n",
      "6   $30K - $50K      F               2                     1   \n",
      "7   $50K - $70K      M               2                     2   \n",
      "8   $10K - $30K      M               5                     3   \n",
      "9   $30K - $50K      M               4                     0   \n",
      "\n",
      "             education acct_open_date member_card      occupation homeowner  \n",
      "0  Partial High School      9/10/1991      Bronze  Skilled Manual         Y  \n",
      "1  Partial High School      3/11/1993      Bronze    Professional         N  \n",
      "2     Bachelors Degree      6/11/1991      Bronze    Professional         Y  \n",
      "3  Partial High School      5/21/1994      Normal  Skilled Manual         N  \n",
      "4      Partial College      8/21/1992      Silver          Manual         N  \n",
      "5     Bachelors Degree       4/5/1992      Bronze    Professional         Y  \n",
      "6  Partial High School       5/1/1991      Bronze          Manual         Y  \n",
      "7     Bachelors Degree      6/11/1992      Bronze    Professional         Y  \n",
      "8  Partial High School     11/14/1993      Normal  Skilled Manual         Y  \n",
      "9     Bachelors Degree       5/4/1993      Golden      Management         N  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('MavenMarket_Customers.csv')\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8788ef1-8474-4e6c-8aa8-42c61d14e651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id  customer_acct_num first_name  last_name  \\\n",
      "0            1        87462024688      Sheri     Nowmer   \n",
      "1            2        87470586299    Derrick    Whelply   \n",
      "2            3        87475757600     Jeanne      Derry   \n",
      "3            4        87500482201    Michael     Spence   \n",
      "4            5        87514054179       Maya  Gutierrez   \n",
      "5            6        87517782449     Robert    Damstra   \n",
      "6            7        87521172800    Rebecca   Kanagaki   \n",
      "7            8        87539744377        Kim    Brunner   \n",
      "8            9        87544797658     Brenda   Blumberg   \n",
      "9           10        87568712234     Darren      Stanz   \n",
      "\n",
      "         customer_address customer_city customer_state_province  \\\n",
      "0        2433 Bailey Road      Tlaxiaco                  Oaxaca   \n",
      "1      2219 Dewing Avenue         Sooke                      BC   \n",
      "2         7640 First Ave.      Issaquah                      WA   \n",
      "3           337 Tosca Way       Burnaby                      BC   \n",
      "4         8668 Via Neruda        Novato                      CA   \n",
      "5     1619 Stillman Court      Lynnwood                      WA   \n",
      "6  2860 D Mt. Hood Circle      Tlaxiaco                  Oaxaca   \n",
      "7       6064 Brodia Court    San Andres                      DF   \n",
      "8        7560 Trees Drive      Richmond                      BC   \n",
      "9         1019 Kenwal Rd.   Lake Oswego                      OR   \n",
      "\n",
      "   customer_postal_code customer_country  birthdate  ... yearly_income gender  \\\n",
      "0                 15057           Mexico  8/26/1961  ...   $30K - $50K      F   \n",
      "1                 17172           Canada   7/3/1915  ...   $70K - $90K      M   \n",
      "2                 73980              USA  6/21/1910  ...   $50K - $70K      F   \n",
      "3                 74674           Canada  6/20/1969  ...   $10K - $30K      M   \n",
      "4                 57355              USA  5/10/1951  ...   $30K - $50K      F   \n",
      "5                 90792              USA  10/8/1942  ...   $70K - $90K      F   \n",
      "6                 13343           Mexico  3/27/1949  ...   $30K - $50K      F   \n",
      "7                 12942           Mexico  8/10/1922  ...   $50K - $70K      M   \n",
      "8                 17256           Canada  6/23/1979  ...   $10K - $30K      M   \n",
      "9                 82017              USA  8/26/1949  ...   $30K - $50K      M   \n",
      "\n",
      "  total_children  num_children_at_home            education acct_open_date  \\\n",
      "0              4                     2  Partial High School      9/10/1991   \n",
      "1              1                     0  Partial High School      3/11/1993   \n",
      "2              1                     1     Bachelors Degree      6/11/1991   \n",
      "3              4                     4  Partial High School      5/21/1994   \n",
      "4              3                     0      Partial College      8/21/1992   \n",
      "5              3                     0     Bachelors Degree       4/5/1992   \n",
      "6              2                     1  Partial High School       5/1/1991   \n",
      "7              2                     2     Bachelors Degree      6/11/1992   \n",
      "8              5                     3  Partial High School     11/14/1993   \n",
      "9              4                     0     Bachelors Degree       5/4/1993   \n",
      "\n",
      "  member_card      occupation homeowner         Full Name  \n",
      "0      Bronze  Skilled Manual         Y      Sheri Nowmer  \n",
      "1      Bronze    Professional         N   Derrick Whelply  \n",
      "2      Bronze    Professional         Y      Jeanne Derry  \n",
      "3      Normal  Skilled Manual         N    Michael Spence  \n",
      "4      Silver          Manual         N    Maya Gutierrez  \n",
      "5      Bronze    Professional         Y    Robert Damstra  \n",
      "6      Bronze          Manual         Y  Rebecca Kanagaki  \n",
      "7      Bronze    Professional         Y       Kim Brunner  \n",
      "8      Normal  Skilled Manual         Y   Brenda Blumberg  \n",
      "9      Golden      Management         N      Darren Stanz  \n",
      "\n",
      "[10 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a column FUll name from existing columns first_name and Last_name and capitalize both columns\n",
    "\n",
    "data['Full Name'] = data['first_name'].str.capitalize() + ' ' +  data['last_name'].str.capitalize()\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8133a729-bb4c-46d7-9c50-494398419d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column transformation in pandas part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5cdd9e2-000a-4ae3-b696-b3142355d9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary\n",
      "0  EMP01    ayushi      F  24000.0\n",
      "1  EMP02     rohit      M  25000.0\n",
      "2  EMP03  pranjali    NaN  27000.0\n",
      "3  EMP01    ayushi      F  20000.0\n",
      "4  EMP05       NaN      M  25000.0\n",
      "5  EMP06     rohit      M  24000.0\n",
      "6  EMP02     rohit      M  25000.0\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('company1.csv')\n",
    "data['salary'] = data['salary'].fillna(24000)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f564da5e-8655-497d-b819-5e4a40ba20f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EEID      Name gender   salary   Bonus\n",
      "0  EMP01    ayushi      F  24000.0  4800.0\n",
      "1  EMP02     rohit      M  25000.0  5000.0\n",
      "2  EMP03  pranjali    NaN  27000.0  5400.0\n",
      "3  EMP01    ayushi      F  20000.0  4000.0\n",
      "4  EMP05       NaN      M  25000.0  5000.0\n",
      "5  EMP06     rohit      M  24000.0  4800.0\n",
      "6  EMP02     rohit      M  25000.0  5000.0\n"
     ]
    }
   ],
   "source": [
    "# create a column bonus to give 20% bonus on salary\n",
    "\n",
    "data['Bonus'] = (data['salary']/100)*20\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f2f9531-1ac0-4f65-afac-682423099656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Months Short_Months\n",
      "0    January          Jan\n",
      "1   February           Fe\n",
      "2      March          Mar\n",
      "3      April          Apr\n"
     ]
    }
   ],
   "source": [
    "# create a column short month using the month column to populate the short name for the month.\n",
    "\n",
    "month = {'Months':['January',' February', 'March', 'April']}\n",
    "data = pd.DataFrame(month)\n",
    "\n",
    "def extract_sliced_value(value):\n",
    "    return value[0:3]\n",
    "\n",
    "data['Short_Months'] = data['Months'].map(extract_sliced_value)\n",
    "\n",
    "print(data)\n",
    "\n",
    "# Note - we made a function for slicing the value and using the map method mapped the value to a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbdde219-60f0-4cf1-b38b-8744c8d91091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e76fcbee-21d3-47cd-9ef4-c45554595e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     EEID        Full Name                 Job Title  Department  \\\n",
      "0  E02387      Emily Davis                Sr. Manger          IT   \n",
      "1  E04105    Theodore Dinh       Technical Architect          IT   \n",
      "2  E02572     Luna Sanders                  Director     Finance   \n",
      "3  E02832  Penelope Jordan  Computer Systems Manager          IT   \n",
      "4  E01639        Austin Vo               Sr. Analyst     Finance   \n",
      "5  E00644     Joshua Gupta    Account Representative       Sales   \n",
      "6  E01550      Ruby Barnes                   Manager          IT   \n",
      "7  E04332      Luke Martin                   Analyst     Finance   \n",
      "8  E04533    Easton Bailey                   Manager  Accounting   \n",
      "9  E03838  Madeline Walker               Sr. Analyst     Finance   \n",
      "\n",
      "            Business Unit  Gender  Ethnicity  Age  Hire Date  Annual Salary  \\\n",
      "0  Research & Development  Female      Black   55 2016-04-08         141604   \n",
      "1           Manufacturing    Male      Asian   59 1997-11-29          99975   \n",
      "2     Speciality Products  Female  Caucasian   50 2006-10-26         163099   \n",
      "3           Manufacturing  Female  Caucasian   26 2019-09-27          84913   \n",
      "4           Manufacturing    Male      Asian   55 1995-11-20          95409   \n",
      "5               Corporate    Male      Asian   57 2017-01-24          50994   \n",
      "6               Corporate  Female  Caucasian   27 2020-07-01         119746   \n",
      "7           Manufacturing    Male      Black   25 2020-05-16          41336   \n",
      "8           Manufacturing    Male  Caucasian   29 2019-01-25         113527   \n",
      "9     Speciality Products  Female  Caucasian   34 2018-06-13          77203   \n",
      "\n",
      "   Bonus %        Country       City  Exit Date  \n",
      "0     0.15  United States    Seattle 2021-10-16  \n",
      "1     0.00          China  Chongqing        NaT  \n",
      "2     0.20  United States    Chicago        NaT  \n",
      "3     0.07  United States    Chicago        NaT  \n",
      "4     0.00  United States    Phoenix        NaT  \n",
      "5     0.00          China  Chongqing        NaT  \n",
      "6     0.10  United States    Phoenix        NaT  \n",
      "7     0.00  United States      Miami 2021-05-20  \n",
      "8     0.06  United States     Austin        NaT  \n",
      "9     0.00  United States    Chicago        NaT  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('ESD.xlsx')\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c76ebb3-50f1-4a3d-9242-6b3952a6c0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      EEID\n",
      "Country       Department      Gender      \n",
      "Brazil        Accounting      Female     7\n",
      "                              Male       3\n",
      "              Engineering     Female    17\n",
      "                              Male      15\n",
      "              Finance         Female     9\n",
      "                              Male       9\n",
      "              Human Resources Female    11\n",
      "                              Male       8\n",
      "              IT              Female    12\n",
      "                              Male      14\n",
      "              Marketing       Female     6\n",
      "                              Male       7\n",
      "              Sales           Female    13\n",
      "                              Male       8\n",
      "China         Accounting      Female    10\n",
      "                              Male      10\n",
      "              Engineering     Female    17\n",
      "                              Male      12\n",
      "              Finance         Female    19\n",
      "                              Male       9\n",
      "              Human Resources Female    12\n",
      "                              Male      13\n",
      "              IT              Female    22\n",
      "                              Male      28\n",
      "              Marketing       Female    14\n",
      "                              Male      21\n",
      "              Sales           Female    15\n",
      "                              Male      16\n",
      "United States Accounting      Female    36\n",
      "                              Male      30\n",
      "              Engineering     Female    46\n",
      "                              Male      51\n",
      "              Finance         Female    41\n",
      "                              Male      33\n",
      "              Human Resources Female    41\n",
      "                              Male      40\n",
      "              IT              Female    85\n",
      "                              Male      80\n",
      "              Marketing       Female    37\n",
      "                              Male      35\n",
      "              Sales           Female    48\n",
      "                              Male      40\n"
     ]
    }
   ],
   "source": [
    "# It provides a count of EEID values for each distinct combination of Country, Department, and Gender in the dataset.\n",
    "gp = data.groupby(['Country','Department','Gender']).agg({'EEID':'count'})\n",
    "print(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db0b28c7-a1f2-47cb-8433-70fb55548f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Annual Salary\n",
      "Country                     \n",
      "Brazil                258426\n",
      "China                 257194\n",
      "United States         258498\n"
     ]
    }
   ],
   "source": [
    "gp = data.groupby('Country').agg({'Annual Salary':'max'})\n",
    "print(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5ba33e3-d409-4951-b5bc-e840fb38de46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Annual Salary        Age\n",
      "Country                                \n",
      "Brazil                258426  43.654676\n",
      "China                 257194  45.389908\n",
      "United States         258498  44.197512\n"
     ]
    }
   ],
   "source": [
    "gp = data.groupby('Country').agg({'Annual Salary':'max','Age':'mean'})\n",
    "print(gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64e96835-d23e-4718-93e1-f0833b3eaf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge, Join and concatenate in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f598adfc-1ef8-459d-8356-cb48e93564d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmpId  Names  Age\n",
      "0  E001    Ram   30\n",
      "1  E002  Shyam   24\n",
      "2  E003  Rohan   35\n",
      "  EmpId  Salary\n",
      "0  E001   30000\n",
      "1  E002   24000\n",
      "2  E003   35000\n"
     ]
    }
   ],
   "source": [
    "data1 = {\"EmpId\":[\"E001\",\"E002\",\"E003\"],\n",
    "        \"Names\":[\"Ram\",\"Shyam\",\"Rohan\"],\n",
    "        \"Age\": [30,24,35]}\n",
    "data2 = {\"EmpId\":[\"E001\",\"E002\",\"E003\"],\n",
    "        \"Salary\": [30000,24000,35000]}\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d27d90d-11fe-4d62-8c85-78d60af62deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmpId  Names  Age  Salary\n",
      "0  E001    Ram   30   30000\n",
      "1  E002  Shyam   24   24000\n",
      "2  E003  Rohan   35   35000\n"
     ]
    }
   ],
   "source": [
    "# merge function is a common operation used to combine data from different sources like a join\n",
    "new_df = pd.merge(left=df1,right=df2,on='EmpId',how='inner')\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "276a0c59-44f4-4724-80fe-592381a7eb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmpId  Names  Age  Salary\n",
      "0  E001    Ram   30   30000\n",
      "1  E002  Shyam   24   24000\n",
      "2  E003  Rohan   35   35000\n"
     ]
    }
   ],
   "source": [
    "new_df = pd.merge(left=df1,right=df2,on='EmpId',how='left')\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a7270d3d-b8f9-4763-8bfd-df4becf37ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmpId  Names   Age   Salary\n",
      "0  E001    Ram  30.0      NaN\n",
      "1  E002  Shyam  24.0      NaN\n",
      "2  E003  Rohan  35.0      NaN\n",
      "3  E001    NaN   NaN  30000.0\n",
      "4  E002    NaN   NaN  24000.0\n",
      "5  E003    NaN   NaN  35000.0\n"
     ]
    }
   ],
   "source": [
    "# The concat method in Pandas is used to concatenate two or more dataframes along a particular axis\n",
    "\n",
    "new_df = pd.concat((df1,df2), axis=0, join='outer', ignore_index=True)\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "33f288ca-5840-4450-b887-5d70cca5e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing dataframes is a common task that helps identify differences or similarities between them. \n",
    "\n",
    "data1 = {\"EmpId\":[\"E001\",\"E002\",\"E003\"],\n",
    "        \"Names\":[\"Ram\",\"Shyam\",\"Rohan\"],\n",
    "        \"Age\": [30,24,35]}\n",
    "data2 = {\"EmpId\":[\"E001\",\"E004\",\"E003\"],\n",
    "        \"Names\":[\"Ram\",\"Shyam\",\"Rohan\"],\n",
    "        \"Age\": [30,24,35]}\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "910f358a-1931-4261-b4cf-65f7ed4306d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(df1.equals(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7cfe7b6e-44df-4f01-88b5-3ec8adc147a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmpId      \n",
      "   self other\n",
      "1  E002  E004\n"
     ]
    }
   ],
   "source": [
    "result = df1.compare(df2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf6df7b1-27ce-4cc3-a5b0-dc28787b0285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas - Pivoting and melting DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2307e13b-43a8-4ee6-b652-d91e7bb09960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivoting in Pandas is a technique used to reshape data, allowing you to transform or reorganize dataframes for better analysis.\n",
    "\n",
    "# The pivot() method is used to create a new dataframe by specifying which columns to use for the new index, columns, and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eec8f4f8-079c-45d3-bcda-ae8bfd3695ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'date': ['2024-01-01', '2024-01-01', '2024-01-02', '2024-01-02'],\n",
    "    'city': ['New York', 'Los Angeles', 'New York', 'Los Angeles'],\n",
    "    'temperature': [30, 70, 32, 68],\n",
    "    'age': [10, 12, 34, 21]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d3350905-f046-4013-8f22-d6fb08854f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           temperature         \n",
      "city       Los Angeles New York\n",
      "date                           \n",
      "2024-01-01          70       30\n",
      "2024-01-02          68       32\n"
     ]
    }
   ],
   "source": [
    "pivot_df = df.pivot(index='date', columns='city', values=['temperature'])\n",
    "\n",
    "print(pivot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9163f24d-6f73-42a9-aa5d-94953f5f4095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   age          temperature         \n",
      "city       Los Angeles New York Los Angeles New York\n",
      "date                                                \n",
      "2024-01-01        12.0     10.0        70.0     30.0\n",
      "2024-01-02        21.0     34.0        68.0     32.0\n"
     ]
    }
   ],
   "source": [
    "pivot_df = df.pivot_table(index='date', columns='city', values=['temperature', 'age'])\n",
    "\n",
    "print(pivot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e8156dda-16da-4ec2-95af-9a20062e27d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melting in pandas \n",
    "\n",
    "# Melting in Pandas is a technique used to transform a wide-format dataframe into a long-format dataframe. \n",
    "# This is particularly useful for reshaping data so that it can be more easily analyzed or visualized.\n",
    "\n",
    "data = {\n",
    "    'date': ['2024-01-01', '2024-01-02'],\n",
    "    'city': ['New York', 'Los Angeles'],\n",
    "    'temperature': [30, 32],\n",
    "    'humidity': [50, 60]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3e956a05-4d3c-4218-9c59-7634a7692c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date         city  temperature  humidity\n",
      "0  2024-01-01     New York           30        50\n",
      "1  2024-01-02  Los Angeles           32        60\n",
      "\n",
      "         date         city  measurement  value\n",
      "0  2024-01-01     New York  temperature     30\n",
      "1  2024-01-02  Los Angeles  temperature     32\n",
      "2  2024-01-01     New York     humidity     50\n",
      "3  2024-01-02  Los Angeles     humidity     60\n"
     ]
    }
   ],
   "source": [
    "melted_df = pd.melt(df, id_vars=['date', 'city'], value_vars=['temperature', 'humidity'], \n",
    "                    var_name='measurement', value_name='value')\n",
    "print(df)\n",
    "print()\n",
    "print(melted_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
